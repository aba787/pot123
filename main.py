import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
from PIL import Image
import pandas as pd
import numpy as np
import json
import re
from datetime import datetime
import requests
import io
import easyocr
import cv2
from typing import Dict, List, Tuple, Optional

class DrugAPIHandler:
    def __init__(self):
        # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        self.mock_drug_database = {
            "paracetamol": {
                "name_ar": "Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„",
                "name_en": "Paracetamol",
                "concentrations": ["500mg", "1000mg", "120mg/5ml"],
                "general_use_ar": "Ù…Ø³ÙƒÙ† Ù„Ù„Ø£Ù„Ù… ÙˆØ®Ø§ÙØ¶ Ù„Ù„Ø­Ø±Ø§Ø±Ø©",
                "general_use_en": "Pain reliever and fever reducer",
                "interactions_ar": ["Ø§Ù„ÙƒØ­ÙˆÙ„", "Ø§Ù„ÙˆØ§Ø±ÙØ§Ø±ÙŠÙ†"],
                "interactions_en": ["Alcohol", "Warfarin"],
                "warnings_ar": ["Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 4 Ø¬Ø±Ø§Ù… ÙŠÙˆÙ…ÙŠØ§Ù‹", "Ø­Ø°Ø§Ø± Ù…Ù† Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„ÙƒØ¨Ø¯"],
                "warnings_en": ["Do not exceed 4g daily", "Caution with liver disease"],
                "alternatives_ar": ["Ø¥ÙŠØ¨ÙˆØ¨Ø±ÙˆÙÙŠÙ†", "Ø£Ø³Ø¨Ø±ÙŠÙ†"],
                "alternatives_en": ["Ibuprofen", "Aspirin"],
                "danger_level": "low",
                "pediatric_safe": False,  # NO PEDIATRIC DOSES ALLOWED
                "min_age_months": 0
            },
            "ibuprofen": {
                "name_ar": "Ø¥ÙŠØ¨ÙˆØ¨Ø±ÙˆÙÙŠÙ†", 
                "name_en": "Ibuprofen",
                "concentrations": ["200mg", "400mg", "600mg", "100mg/5ml"],
                "general_use_ar": "Ù…Ø³ÙƒÙ† ÙˆÙ…Ø¶Ø§Ø¯ Ù„Ù„Ø§Ù„ØªÙ‡Ø§Ø¨",
                "general_use_en": "Pain reliever and anti-inflammatory",
                "interactions_ar": ["Ø§Ù„Ø£Ø³Ø¨Ø±ÙŠÙ†", "Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¬Ù„Ø·", "Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ø¶ØºØ·"],
                "interactions_en": ["Aspirin", "Blood thinners", "Blood pressure medications"],
                "warnings_ar": ["ØªØ¬Ù†Ø¨ Ù…Ø¹ Ù‚Ø±Ø­Ø© Ø§Ù„Ù…Ø¹Ø¯Ø©", "Ø­Ø°Ø§Ø± Ù…Ø¹ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„ÙƒÙ„Ù‰"],
                "warnings_en": ["Avoid with stomach ulcers", "Caution with kidney disease"],
                "alternatives_ar": ["Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„", "Ù†Ø§Ø¨Ø±ÙˆÙƒØ³ÙŠÙ†"],
                "alternatives_en": ["Paracetamol", "Naproxen"],
                "danger_level": "medium",
                "pediatric_safe": False,  # NO PEDIATRIC DOSES ALLOWED
                "min_age_months": 6
            },
            "cetirizine": {
                "name_ar": "Ø³ÙŠØªÙŠØ±ÙŠØ²ÙŠÙ†",
                "name_en": "Cetirizine",
                "concentrations": ["10mg", "5mg/5ml"],
                "general_use_ar": "Ù…Ø¶Ø§Ø¯ Ù„Ù„Ø­Ø³Ø§Ø³ÙŠØ©",
                "general_use_en": "Antihistamine for allergies",
                "interactions_ar": ["Ø§Ù„ÙƒØ­ÙˆÙ„", "Ø§Ù„Ù…Ù‡Ø¯Ø¦Ø§Øª"],
                "interactions_en": ["Alcohol", "Sedatives"],
                "warnings_ar": ["Ù‚Ø¯ ÙŠØ³Ø¨Ø¨ Ù†Ø¹Ø§Ø³", "ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©"],
                "warnings_en": ["May cause drowsiness", "Avoid driving"],
                "alternatives_ar": ["Ù„ÙˆØ±Ø§ØªØ§Ø¯ÙŠÙ†", "ÙÙŠÙƒØ³ÙˆÙÙŠÙ†Ø§Ø¯ÙŠÙ†"],
                "alternatives_en": ["Loratadine", "Fexofenadine"],
                "danger_level": "low",
                "pediatric_safe": False,  # NO PEDIATRIC DOSES ALLOWED
                "min_age_months": 6
            },
            "loratadine": {
                "name_ar": "Ù„ÙˆØ±Ø§ØªØ§Ø¯ÙŠÙ†",
                "name_en": "Loratadine",
                "concentrations": ["10mg", "5mg/5ml"],
                "general_use_ar": "Ù…Ø¶Ø§Ø¯ Ù„Ù„Ø­Ø³Ø§Ø³ÙŠØ© ØºÙŠØ± Ù…Ù†ÙˆÙ…",
                "general_use_en": "Non-drowsy antihistamine",
                "interactions_ar": ["Ù‚Ù„ÙŠÙ„Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„"],
                "interactions_en": ["Few interactions"],
                "warnings_ar": ["Ø¢Ù…Ù† Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙŠÙˆÙ…ÙŠ"],
                "warnings_en": ["Safe for daily use"],
                "alternatives_ar": ["Ø³ÙŠØªÙŠØ±ÙŠØ²ÙŠÙ†", "ÙÙŠÙƒØ³ÙˆÙÙŠÙ†Ø§Ø¯ÙŠÙ†"],
                "alternatives_en": ["Cetirizine", "Fexofenadine"],
                "danger_level": "low",
                "pediatric_safe": False,  # NO PEDIATRIC DOSES ALLOWED
                "min_age_months": 24
            },
            "dextromethorphan": {
                "name_ar": "Ø¯ÙŠÙƒØ³ØªØ±ÙˆÙ…ÙŠØ«ÙˆØ±ÙØ§Ù†",
                "name_en": "Dextromethorphan",
                "concentrations": ["15mg/5ml", "30mg"],
                "general_use_ar": "Ù…Ø¶Ø§Ø¯ Ù„Ù„Ø³Ø¹Ø§Ù„ Ø§Ù„Ø¬Ø§Ù",
                "general_use_en": "Dry cough suppressant",
                "interactions_ar": ["Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨", "MAO inhibitors"],
                "interactions_en": ["Antidepressants", "MAO inhibitors"],
                "warnings_ar": ["Ù„Ø§ ÙŠØ³ØªØ®Ø¯Ù… Ù…Ø¹ Ø§Ù„Ø³Ø¹Ø§Ù„ Ø§Ù„Ù…ØµØ­ÙˆØ¨ Ø¨Ø¨Ù„ØºÙ…"],
                "warnings_en": ["Not for productive cough"],
                "alternatives_ar": ["Ø§Ù„Ø¹Ø³Ù„", "Ø£Ø¯ÙˆÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ©"],
                "alternatives_en": ["Honey", "Natural remedies"],
                "danger_level": "low",
                "pediatric_safe": False,  # NO PEDIATRIC DOSES ALLOWED
                "min_age_months": 24
            }
        }

    def search_drug(self, drug_name: str, language: str = 'ar') -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¯ÙˆØ§Ø¡ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        drug_name_clean = drug_name.lower().strip()

        for key, drug_info in self.mock_drug_database.items():
            if (drug_name_clean in key.lower() or 
                drug_name_clean in drug_info.get('name_ar', '').lower() or
                drug_name_clean in drug_info.get('name_en', '').lower()):
                return drug_info

        return None

class MedicalSafetyChecker:
    def __init__(self):
        # Ù‚Ø§Ø¦Ù…Ø© Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ© Ø¨ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„
        self.child_keywords = {
            'ar': [
                'Ø·ÙÙ„', 'Ø·ÙÙ„ÙŠ', 'ÙˆÙ„Ø¯ÙŠ', 'Ø¨Ù†ØªÙŠ', 'Ø§Ù„Ø¹Ù…Ø±', 'Ø¹Ù…Ø±Ù‡', 'Ø¹Ù…Ø±Ù‡Ø§', 
                'Ø³Ù†Ø©', 'Ø³Ù†ÙŠÙ†', 'Ø´Ù‡Ø±', 'Ø£Ø´Ù‡Ø±', 'ÙˆØ²Ù†Ù‡', 'ÙˆØ²Ù†Ù‡Ø§', 'Ø±Ø¶ÙŠØ¹', 
                'Ù…ÙˆÙ„ÙˆØ¯', 'Ù…ÙˆØ§Ù„ÙŠØ¯', 'Ø·ÙÙ„Ø©', 'ØµØ¨ÙŠ', 'Ø¨Ù†ÙŠØ©'
            ],
            'en': [
                'child', 'my child', 'my son', 'my daughter', 'baby', 'infant',
                'toddler', 'kid', 'years old', 'months old', 'age', 'weight'
            ]
        }

        # Ù‚Ø§Ø¦Ù…Ø© Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ© Ø¨ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø­ÙˆØ§Ù…Ù„
        self.pregnancy_keywords = {
            'ar': [
                'Ø­Ø§Ù…Ù„', 'Ø­Ù…Ù„', 'Ù…Ø±Ø¶Ø¹Ø©', 'Ø±Ø¶Ø§Ø¹Ø©', 'ÙˆÙ„Ø¯Øª', 'Ø¨Ø¹Ø¯ Ø§Ù„ÙˆÙ„Ø§Ø¯Ø©',
                'Ø­Ù…Ù„ÙŠ', 'Ø¬Ù†ÙŠÙ†ÙŠ', 'Ø§Ù„Ø­Ù…Ù„', 'Ø§Ù„Ø±Ø¶Ø§Ø¹Ø©'
            ],
            'en': [
                'pregnant', 'pregnancy', 'breastfeeding', 'nursing', 'expecting',
                'maternity', 'prenatal', 'postnatal'
            ]
        }

        # Ù‚Ø§Ø¦Ù…Ø© Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ© Ø¨ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦
        self.emergency_keywords = {
            'ar': [
                'Ø¶ÙŠÙ‚Ø© Ù†ÙØ³', 'Ø¶ÙŠÙ‚ Ù†ÙØ³', 'ØµØ¹ÙˆØ¨Ø© ØªÙ†ÙØ³', 'Ø§Ø®ØªÙ†Ø§Ù‚', 'Ø£Ù„Ù… ØµØ¯Ø±',
                'Ø¥ØºÙ…Ø§Ø¡', 'ÙÙ‚Ø¯Ø§Ù† ÙˆØ¹ÙŠ', 'ØªÙØ±ÙŠØº Ø¯Ù…', 'Ù‚ÙŠØ¡ Ø¯Ù…', 'Ø¨Ø±Ø§Ø² Ø£Ø³ÙˆØ¯',
                'Ø­Ø³Ø§Ø³ÙŠØ© Ø´Ø¯ÙŠØ¯Ø©', 'Ø·ÙØ­ Ø¬Ù„Ø¯ÙŠ Ù‚ÙˆÙŠ', 'ØªÙˆØ±Ù… ÙˆØ¬Ù‡', 'ØªÙˆØ±Ù… Ø§Ù„ÙˆØ¬Ù‡',
                'Ù†ÙˆØ¨Ø© Ù‚Ù„Ø¨ÙŠØ©', 'Ø¬Ù„Ø·Ø©', 'Ø´Ù„Ù„', 'ØªØ´Ù†Ø¬', 'Ù†ÙˆØ¨Ø© ØµØ±Ø¹'
            ],
            'en': [
                'shortness of breath', 'chest pain', 'heart attack', 'stroke',
                'fainting', 'unconscious', 'vomiting blood', 'black stool',
                'severe allergy', 'facial swelling', 'choking', 'seizure'
            ]
        }

    def check_safety_violations(self, user_input: str, language: str) -> Dict:
        """ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§ÙƒØ§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø·Ø¨ÙŠØ© 100%"""
        user_input_lower = user_input.lower()

        # 1) ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„ - Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹
        child_words = self.child_keywords.get(language, [])
        for word in child_words:
            if word in user_input_lower:
                return {
                    'violation': True,
                    'type': 'child_detected',
                    'action': 'refer_to_pharmacist',
                    'message_ar': 'Ù‡Ø°Ù‡ Ø­Ø§Ù„Ø© Ø£Ø·ÙØ§Ù„ØŒ ÙˆØ¬Ø±Ø¹Ø§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„ Ù„Ø§Ø²Ù… ØªÙØ­Ø³Ø¨ Ø­Ø³Ø¨ Ø§Ù„ÙˆØ²Ù† ÙˆØ§Ù„Ø¹Ù…Ø±. ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„ØµÙŠØ¯Ù„ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©.',
                    'message_en': 'This is a pediatric case. Child dosages must be calculated based on weight and age. Referring this case directly to pharmacist.'
                }

        # 2) ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø­ÙˆØ§Ù…Ù„ - Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹
        pregnancy_words = self.pregnancy_keywords.get(language, [])
        for word in pregnancy_words:
            if word in user_input_lower:
                return {
                    'violation': True,
                    'type': 'pregnancy_detected',
                    'action': 'refer_to_pharmacist',
                    'message_ar': 'Ø§Ù„Ø­ÙˆØ§Ù…Ù„ ÙˆØ§Ù„Ù…Ø±Ø¶Ø¹Ø§Øª Ù„Ù‡Ù… Ø£Ø¯ÙˆÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©. ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„ØµÙŠØ¯Ù„ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©.',
                    'message_en': 'Pregnant and breastfeeding women have limited medication options. Referring this case directly to pharmacist.'
                }

        # 3) ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ - ØªØ­ÙˆÙŠÙ„ ÙÙˆØ±ÙŠ
        emergency_words = self.emergency_keywords.get(language, [])
        for word in emergency_words:
            if word in user_input_lower:
                return {
                    'violation': True,
                    'type': 'emergency_detected',
                    'action': 'emergency_referral',
                    'message_ar': 'ğŸš¨ Ù‡Ø°Ù‡ Ø¹Ù„Ø§Ù…Ø© Ø®Ø·Ø±. ØªÙˆØ¬Ù‡ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦ ÙÙˆØ±Ø§Ù‹ Ø£Ùˆ Ø§ØªØµÙ„ Ø¨Ù€ 997.',
                    'message_en': 'ğŸš¨ This is a danger sign. Go to emergency immediately or call 997.'
                }

        return {'violation': False}

class AdvancedSymptomParser:
    def __init__(self):
        # Ù‚Ø§Ù…ÙˆØ³ Ø´Ø§Ù…Ù„ Ù„Ù„Ø£Ù„ÙØ§Ø¸ Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ©
        self.slang_normalization = {
            # Ø£Ù„ÙØ§Ø¸ Ø§Ù„Ø£Ù„Ù… Ø§Ù„Ø¹Ø§Ù…Ø©
            'ÙŠØ¹ÙˆØ±Ù†ÙŠ': 'Ø£Ù„Ù…',
            'ÙŠÙˆØ¬Ø¹Ù†ÙŠ': 'Ø£Ù„Ù…', 
            'ØªØ¹ÙˆØ±Ù†ÙŠ': 'Ø£Ù„Ù…',
            'ØªÙˆØ¬Ø¹Ù†ÙŠ': 'Ø£Ù„Ù…',
            'ÙŠØ£Ù„Ù…Ù†ÙŠ': 'Ø£Ù„Ù…',
            'Ù…Ø¤Ù„Ù…': 'Ø£Ù„Ù…',

            # Ø§Ù„Ø­Ù„Ù‚ ÙˆØ§Ù„ØªÙ†ÙØ³
            'Ø­Ù„Ù‚ÙŠ ÙŠÙ„Ø¹Ø¨': 'Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ù„Ù‚',
            'Ø­Ù„Ù‚ÙŠ ÙŠØ­Ø±Ù‚': 'Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ù„Ù‚',
            'Ø­Ù†Ø¬Ø±ØªÙŠ ØªØ¹ÙˆØ±Ù†ÙŠ': 'Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ù„Ù‚',
            'ØµØ¯Ø±ÙŠ ÙŠØ³ÙƒØ±': 'Ø¶ÙŠÙ‚ ØªÙ†ÙØ³',
            'ØµØ¯Ø±ÙŠ Ø¶ÙŠÙ‚': 'Ø¶ÙŠÙ‚ ØªÙ†ÙØ³',
            'Ù…Ø§ Ø£Ù‚Ø¯Ø± Ø£ØªÙ†ÙØ³': 'Ø¶ÙŠÙ‚ ØªÙ†ÙØ³',
            'Ù†ÙØ³ÙŠ Ù‚Ø§Ø·Ø¹': 'Ø¶ÙŠÙ‚ ØªÙ†ÙØ³',

            # Ø§Ù„Ø¨Ø·Ù† ÙˆØ§Ù„Ù…Ø¹Ø¯Ø©
            'Ø¨Ø·Ù†ÙŠ ÙŠÙ„ÙˆÙŠ': 'Ù…ØºØµ',
            'Ø¨Ø·Ù†ÙŠ ÙŠØ¹ÙˆØ±Ù†ÙŠ': 'Ø£Ù„Ù… Ù…Ø¹Ø¯Ø©',
            'Ù…Ø¹Ø¯ØªÙŠ ØªØ¹ÙˆØ±Ù†ÙŠ': 'Ø£Ù„Ù… Ù…Ø¹Ø¯Ø©',
            'Ø¨Ø·Ù†ÙŠ Ù…Ù„ÙˆÙŠ': 'Ù…ØºØµ',
            'Ø£Ø­Ø³ Ø¨Ù„ÙˆÙŠØ§Ù†': 'Ù…ØºØµ',
            'ÙƒØ±Ø´ÙŠ ÙŠØ¹ÙˆØ±Ù†ÙŠ': 'Ø£Ù„Ù… Ù…Ø¹Ø¯Ø©',

            # Ø§Ù„Ø±Ø£Ø³ ÙˆØ§Ù„Ø¹ÙŠÙˆÙ†
            'Ø±Ø§Ø³ Ø«Ù‚ÙŠÙ„': 'ØµØ¯Ø§Ø¹',
            'Ø±Ø§Ø³ÙŠ Ø«Ù‚ÙŠÙ„': 'ØµØ¯Ø§Ø¹',
            'Ø±Ø£Ø³ÙŠ Ø«Ù‚ÙŠÙ„': 'ØµØ¯Ø§Ø¹',
            'Ø±Ø§Ø³ÙŠ ÙŠØ¹ÙˆØ±Ù†ÙŠ': 'ØµØ¯Ø§Ø¹',
            'Ø±Ø£Ø³ÙŠ ÙŠØ¹ÙˆØ±Ù†ÙŠ': 'ØµØ¯Ø§Ø¹',
            'Ø¹ÙŠÙˆÙ†ÙŠ ØªØ­Ø±Ù‚': 'Ø­Ø³Ø§Ø³ÙŠØ© Ø¹ÙŠÙˆÙ†',
            'Ø¹ÙŠÙ†ÙŠ ØªØ¯Ù…Ø¹': 'Ø­Ø³Ø§Ø³ÙŠØ© Ø¹ÙŠÙˆÙ†',
            'Ø¹ÙŠÙˆÙ†ÙŠ Ø­Ù…Ø±Ø§Ø¡': 'Ø§Ù„ØªÙ‡Ø§Ø¨ Ø¹ÙŠÙˆÙ†',

            # Ø§Ù„Ø³Ø¹Ø§Ù„ ÙˆØ§Ù„Ø²ÙƒØ§Ù…
            'ÙƒØ­Ù‡': 'Ø³Ø¹Ø§Ù„',
            'ÙƒØ­Ø©': 'Ø³Ø¹Ø§Ù„',
            'ÙŠÙƒØ­': 'Ø³Ø¹Ø§Ù„',
            'Ø§Ø³Ø¹Ù„': 'Ø³Ø¹Ø§Ù„',
            'Ø§Ø³Ø¹Ø§Ù„': 'Ø³Ø¹Ø§Ù„',
            'Ø£ÙƒØ­': 'Ø³Ø¹Ø§Ù„',
            'Ø§Ù†ÙÙŠ Ù…Ø³Ø¯ÙˆØ¯': 'Ø§Ø­ØªÙ‚Ø§Ù†',
            'Ø§Ù†ÙÙŠ Ø³Ø§ÙŠÙ„': 'Ø±Ø´Ø­',
            'Ù…Ø²ÙƒÙˆÙ…': 'Ø²ÙƒØ§Ù…',

            # Ø§Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„Ø­Ù…Ù‰
            'Ø¹Ù†Ø¯ÙŠ Ø³Ø®ÙˆÙ†Ø©': 'Ø­Ù…Ù‰',
            'Ø­Ø§Ø±': 'Ø­Ù…Ù‰',
            'Ù…Ø­Ù…ÙˆÙ…': 'Ø­Ù…Ù‰',
            'Ø³Ø®Ù†': 'Ø­Ù…Ù‰',

            # Ø£Ø¹Ø±Ø§Ø¶ Ø£Ø®Ø±Ù‰
            'ÙŠÙ„ÙˆØ¹': 'ØºØ«ÙŠØ§Ù†',
            'Ø£Ø¨ÙŠ Ø£ØªÙ‚ÙŠØ£': 'ØºØ«ÙŠØ§Ù†',
            'Ø¯Ø§ÙŠØ®': 'Ø¯ÙˆØ®Ø©',
            'Ø¯ÙˆØ®Ø§Ù†': 'Ø¯ÙˆØ®Ø©',
            'ØªØ¹Ø¨Ø§Ù†': 'ØªØ¹Ø¨ Ø¹Ø§Ù…',
            'Ù…ÙƒØ³Ø±': 'ØªØ¹Ø¨ Ø¹Ø§Ù…',
            'Ù…Ø±Ù‡Ù‚': 'ØªØ¹Ø¨ Ø¹Ø§Ù…'
        }

        # Ù‚Ø§Ù…ÙˆØ³ Ø´Ø§Ù…Ù„ Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©
        self.drug_synonyms = {
            # Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„
            'ÙÙŠÙØ§Ø¯ÙˆÙ„': 'paracetamol',
            'Ø¨Ù†Ø¯ÙˆÙ„': 'paracetamol',
            'Ø¨Ù†Ø§Ø¯ÙˆÙ„': 'paracetamol',
            'Ø£Ø¯ÙˆÙ„': 'paracetamol',
            'ØªØ§ÙŠÙ„ÙŠÙ†ÙˆÙ„': 'paracetamol',
            'Ø³ÙŠØªØ§Ù„': 'paracetamol',
            'Ø³ÙŠØªØ§Ù…ÙˆÙ„': 'paracetamol',
            'Ù†ÙˆÙØ§Ù„Ø¯ÙˆÙ„': 'paracetamol',
            'Ø£ÙƒØ§Ù…ÙˆÙ„': 'paracetamol',
            'Ø±ÙŠÙØ§Ù†ÙŠÙ†': 'paracetamol',
            'panadol': 'paracetamol',
            'fevadol': 'paracetamol',
            'adol': 'paracetamol',
            'tylenol': 'paracetamol',
            'novaldol': 'paracetamol',
            'acamol': 'paracetamol',

            # Ø¥ÙŠØ¨ÙˆØ¨Ø±ÙˆÙÙŠÙ†
            'Ø¨Ø±ÙˆÙÙŠÙ†': 'ibuprofen',
            'Ø£Ø¯ÙÙŠÙ„': 'ibuprofen',
            'Ù†ÙˆØ±ÙˆÙÙŠÙ†': 'ibuprofen',
            'Ø¨Ù„ÙÙŠÙ†': 'ibuprofen',
            'Ù…ÙˆØªØ±ÙŠÙ†': 'ibuprofen',
            'Ø¥ÙŠØ¨ÙˆÙÙŠÙ†': 'ibuprofen',
            'ÙÙ„Ø¯ÙŠÙ†': 'ibuprofen',
            'profin': 'ibuprofen',
            'advil': 'ibuprofen',
            'nurofen': 'ibuprofen',
            'motrin': 'ibuprofen',
            'brufen': 'ibuprofen',

            # Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
            'ÙƒÙ„Ø§Ø±ÙŠØªÙŠÙ†': 'loratadine',
            'ØªÙŠÙ„ÙØ§Ø³Øª': 'fexofenadine',
            'Ø²ÙŠØ±ØªÙƒ': 'cetirizine',
            'Ø£Ù„ÙŠØ±Ø¬ÙŠÙ„': 'cetirizine',
            'Ù‡ÙŠØ³ØªÙˆØ¨': 'cetirizine',
            'claritine': 'loratadine',
            'telfast': 'fexofenadine',
            'zyrtec': 'cetirizine',
            'allergyl': 'cetirizine',

            # Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ø¨Ø±Ø¯ ÙˆØ§Ù„Ø³Ø¹Ø§Ù„
            'Ø¯ÙŠÙƒÙˆÙ„': 'dextromethorphan',
            'ÙÙ„ÙˆØªØ§Ø¨': 'paracetamol',  # Ù…Ø±ÙƒØ¨
            'ÙƒÙˆÙ…ØªØ±ÙŠÙƒØ³': 'paracetamol',  # Ù…Ø±ÙƒØ¨
            'Ù†Ø§ÙŠØª ÙƒÙˆÙ„Ø¯': 'paracetamol',  # Ù…Ø±ÙƒØ¨
            'Ø¯ÙŠÙƒÙˆÙ†Ø¬Ø³ØªÙŠÙ„': 'dextromethorphan',
            'decol': 'dextromethorphan',
            'fluotab': 'paracetamol',
            'comtrex': 'paracetamol',
            'night_cold': 'paracetamol',

            # Ø£Ø®Ø±Ù‰
            'Ø£Ø³Ø¨Ø±ÙŠÙ†': 'aspirin',
            'Ø§Ø³Ø¨Ø±ÙŠÙ†': 'aspirin',
            'aspirin': 'aspirin',
            'Ø§Ø³Ø¨ÙˆØ³ÙŠØ¯': 'aspirin',
            'Ø¬ÙˆØ³Ø¨Ø±ÙŠÙ†': 'aspirin',
            'ÙˆØ§Ø±ÙØ§Ø±ÙŠÙ†': 'warfarin',
            'warfarin': 'warfarin'
        }

    def normalize_text(self, text: str) -> str:
        """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ù…ÙŠ Ø¥Ù„Ù‰ ÙØµÙŠØ­"""
        normalized = text.lower()
        for slang, formal in self.slang_normalization.items():
            normalized = normalized.replace(slang, formal)
        return normalized

    def extract_drug_names(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        text_lower = text.lower()
        found_drugs = []

        for synonym, standard_name in self.drug_synonyms.items():
            if synonym in text_lower:
                found_drugs.append(standard_name)

        return list(set(found_drugs))  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±

class DecisionTreeClassifier:
    def __init__(self):
        self.symptom_parser = AdvancedSymptomParser()
        self.drug_api = DrugAPIHandler()
        self.safety_checker = MedicalSafetyChecker()

        # Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù„ÙƒÙ„ Ø¹Ø±Ø¶ (Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ù„Ù…Ø·Ù„ÙˆØ¨)
        self.symptom_responses = {
            # ÙƒØ­Ø© Ù†Ø§Ø´ÙØ©
            'ÙƒØ­Ø© Ù†Ø§Ø´ÙØ©': {
                'response_ar': """ğŸ’Š Ù„Ù„ÙƒØ­Ø© Ø§Ù„Ù†Ø§Ø´ÙØ©:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Ù…Ù‡Ø¯Ø¦ ÙƒØ­Ø© Ù…Ø«Ù„ Tussivan C Ø£Ùˆ Decol
â€¢ Ø§Ø´Ø±Ø¨ Ø³ÙˆØ§Ø¦Ù„ Ø¯Ø§ÙØ¦Ø© ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ù‡ÙŠØ¬Ø§Øª
âš ï¸ Ø¥Ø°Ø§ Ù…Ø§ ØªØ­Ø³Ù†Øª 3 Ø£ÙŠØ§Ù…ØŒ Ø±Ø§Ø¬Ø¹ Ø·Ø¨ÙŠØ¨.""",
                'response_en': """ğŸ’Š For dry cough:
â€¢ Suggested medication: Cough suppressant like Tussivan C or Decol
â€¢ Drink warm fluids and avoid irritants
âš ï¸ If no improvement in 3 days, see doctor."""
            },

            # ÙƒØ­Ø© Ù…Ø¹ Ø¨Ù„ØºÙ…
            'Ø¨Ù„ØºÙ…': {
                'response_ar': """ğŸ’Š Ù„Ù„Ø¨Ù„ØºÙ…:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Ù…Ø°ÙŠØ¨ Ø¨Ù„ØºÙ… Ù…Ø«Ù„ Mucosolvan
â€¢ Ø§Ø´Ø±Ø¨ Ø³ÙˆØ§Ø¦Ù„ ÙƒØ«ÙŠØ±Ø©
âš ï¸ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± 3 Ø£ÙŠØ§Ù…ØŒ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¨.""",
                'response_en': """ğŸ’Š For phlegm:
â€¢ Suggested medication: Mucolytic like Mucosolvan
â€¢ Drink plenty of fluids
âš ï¸ If continues for 3 days, see doctor."""
            },

            # Ø­Ø±Ø§Ø±Ø© (Ø¨Ø§Ù„Øº)
            'Ø­Ø±Ø§Ø±Ø©': {
                'response_ar': """ğŸ’Š Ù„Ù„Ø­Ø±Ø§Ø±Ø©:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„
â€¢ Ø®Ø° Ø±Ø§Ø­Ø© ÙˆØ§Ø´Ø±Ø¨ Ø³ÙˆØ§Ø¦Ù„
âš ï¸ Ø¥Ø°Ø§ Ø§Ø±ØªÙØ¹Øª Ø£Ùˆ Ø§Ø³ØªÙ…Ø±Øª 3 Ø£ÙŠØ§Ù…ØŒ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¨.""",
                'response_en': """ğŸ’Š For fever:
â€¢ Suggested medication: Paracetamol
â€¢ Rest and drink fluids
âš ï¸ If rises or continues 3 days, see doctor."""
            },

            # ØµØ¯Ø§Ø¹
            'ØµØ¯Ø§Ø¹': {
                'response_ar': """ğŸ’Š Ù„Ù„ØµØ¯Ø§Ø¹:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Ù…Ø³ÙƒÙ† Ø¨Ø³ÙŠØ· Ù…Ø«Ù„ Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„
â€¢ Ø§Ø±ØªØ­ ÙˆØ§Ø´Ø±Ø¨ Ù…Ø§Ø¡
âš ï¸ Ø¥Ø°Ø§ Ø§Ù„ØµØ¯Ø§Ø¹ Ø´Ø¯ÙŠØ¯ ÙˆÙ…ØªÙƒØ±Ø±ØŒ Ø§ÙØ­Øµ.""",
                'response_en': """ğŸ’Š For headache:
â€¢ Suggested medication: Simple painkiller like Paracetamol
â€¢ Rest and drink water
âš ï¸ If severe and recurring, get checked."""
            },

            # Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ù„Ù‚
            'Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ù„Ù‚': {
                'response_ar': """ğŸ’Š Ù„Ø§Ù„ØªÙ‡Ø§Ø¨ Ø§Ù„Ø­Ù„Ù‚:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Lozenges Ø£Ùˆ ØºØ±ØºØ±Ø© Ù…Ù„Ø­ Ø¯Ø§ÙØ¦
â€¢ Ø§Ø´Ø±Ø¨ Ø³ÙˆØ§Ø¦Ù„ Ø¯Ø§ÙØ¦Ø©
âš ï¸ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± Ø£ÙƒØ«Ø± Ù…Ù† 3 Ø£ÙŠØ§Ù…ØŒ Ø±Ø§Ø¬Ø¹ Ø·Ø¨ÙŠØ¨.""",
                'response_en': """ğŸ’Š For sore throat:
â€¢ Suggested medication: Lozenges or warm salt gargle
â€¢ Drink warm fluids
âš ï¸ If continues more than 3 days, see doctor."""
            },

            # Ø§Ø­ØªÙ‚Ø§Ù† ÙˆØ§Ù†Ø³Ø¯Ø§Ø¯ Ø§Ù„Ø£Ù†Ù
            'Ø§Ø­ØªÙ‚Ø§Ù†': {
                'response_ar': """ğŸ’Š Ù„Ù„Ø§Ø­ØªÙ‚Ø§Ù†:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Ù…Ø²ÙŠÙ„ Ø§Ø­ØªÙ‚Ø§Ù† Ù…Ø«Ù„ Sudafed
â€¢ Ø¨Ø®Ø§Ø± Ù…Ø§Ø¡ Ø¯Ø§ÙØ¦ ÙŠØ³Ø§Ø¹Ø¯""",
                'response_en': """ğŸ’Š For congestion:
â€¢ Suggested medication: Decongestant like Sudafed
â€¢ Warm steam helps"""
            },

            # Ø¯ÙˆØ®Ø© ÙˆØºØ«ÙŠØ§Ù†
            'Ø¯ÙˆØ®Ø©': {
                'response_ar': """ğŸ’Š Ù„Ù„Ø¯ÙˆØ®Ø© ÙˆØ§Ù„ØºØ«ÙŠØ§Ù†:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Dramamine
â€¢ ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©""",
                'response_en': """ğŸ’Š For dizziness and nausea:
â€¢ Suggested medication: Dramamine
â€¢ Avoid sudden movements"""
            },

            # Ø£Ù„Ù… Ø§Ù„Ù…Ø¹Ø¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø£ÙƒÙ„
            'Ø£Ù„Ù… Ù…Ø¹Ø¯Ø©': {
                'response_ar': """ğŸ’Š Ù„Ø£Ù„Ù… Ø§Ù„Ù…Ø¹Ø¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø£ÙƒÙ„:
â€¢ Ø¯ÙˆØ§Ø¡ Ù…Ù‚ØªØ±Ø­: Ù…Ø¶Ø§Ø¯ Ø­Ù…ÙˆØ¶Ø© Ù…Ø«Ù„ Gaviscon
â€¢ ØªØ¬Ù†Ø¨ Ø§Ù„Ø£ÙƒÙ„ Ø§Ù„Ø¯Ø³Ù…""",
                'response_en': """ğŸ’Š For stomach pain after eating:
â€¢ Suggested medication: Antacid like Gaviscon
â€¢ Avoid fatty foods"""
            }
        }

    def classify_input(self, user_input: str, language: str) -> Dict:
        """Decision Tree Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø§Ù„Ø¶Ø¨Ø·"""

        # Step 1: ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦
        safety_check = self.safety_checker.check_safety_violations(user_input, language)
        if safety_check['violation']:
            if safety_check['type'] == 'emergency_detected':
                return {'classification': 'Emergency', 'response': safety_check[f'message_{language}']}
            elif safety_check['type'] == 'child_detected':
                return {'classification': 'ChildReferral', 'response': safety_check[f'message_{language}']}
            elif safety_check['type'] == 'pregnancy_detected':
                return {'classification': 'PregnantReferral', 'response': safety_check[f'message_{language}']}

        # Step 2: ÙØ­Øµ Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡
        detected_drugs = self.symptom_parser.extract_drug_names(user_input)
        if detected_drugs:
            return {'classification': 'DrugInfo', 'drugs': detected_drugs}

        # Step 3: ÙØ­Øµ Ø¹Ø±Ø¶ ÙˆØ§Ø¶Ø­
        normalized_text = self.symptom_parser.normalize_text(user_input)
        for symptom, response_data in self.symptom_responses.items():
            if symptom in normalized_text:
                return {
                    'classification': 'SymptomAdvice',
                    'symptom': symptom,
                    'response': response_data[f'response_{language}']
                }

        # Step 4: Ø§Ù„Ù…Ø¯Ø®Ù„ Ù…Ø¨Ù‡Ù…
        return {'classification': 'Clarify'}

class AdvancedMedicalChatbot:
    def __init__(self):
        self.setup_models()
        self.drug_api = DrugAPIHandler()
        self.decision_tree = DecisionTreeClassifier()

    def setup_models(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ mBERT"""
        try:
            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

            self.classifier = pipeline(
                "text-classification",
                model="bert-base-multilingual-cased",
                tokenizer=self.tokenizer,
                device=0 if torch.cuda.is_available() else -1
            )

            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„Ø§Ù…Ø©!")
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")

    def process_query(self, user_input: str, language: str) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ù…Ø¹ Decision Tree Ø§Ù„Ø¬Ø¯ÙŠØ¯"""

        # ØªØ·Ø¨ÙŠÙ‚ Decision Tree
        classification_result = self.decision_tree.classify_input(user_input, language)

        if classification_result['classification'] == 'Emergency':
            return classification_result['response']

        elif classification_result['classification'] == 'ChildReferral':
            return classification_result['response']

        elif classification_result['classification'] == 'PregnantReferral':
            return classification_result['response']

        elif classification_result['classification'] == 'DrugInfo':
            return self.handle_drug_info(classification_result['drugs'], language)

        elif classification_result['classification'] == 'SymptomAdvice':
            return classification_result['response']

        elif classification_result['classification'] == 'Clarify':
            return self.handle_unclear_input(user_input, language)

        return "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"

    def handle_drug_info(self, detected_drugs: List[str], language: str) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¡ - Ø¨Ø¯ÙˆÙ† Ø¬Ø±Ø¹Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹"""
        drug_name = detected_drugs[0]
        drug_info = self.drug_api.search_drug(drug_name)

        if not drug_info:
            if language == 'ar':
                return f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¡ '{drug_name}' ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
            else:
                return f"Drug information for '{drug_name}' not available in database"

        if language == 'ar':
            response = f"ğŸ’Š **{drug_info['name_ar']} ({drug_info['name_en']})**\n\n"
            response += f"ğŸ”¹ **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** {drug_info['general_use_ar']}\n"
            response += f"ğŸ”¹ **ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ù‡Ù…Ø©:** {', '.join(drug_info['warnings_ar'][:2])}\n"

            if drug_info['alternatives_ar']:
                response += f"ğŸ”¹ **Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ø§Ù…Ø©:** {', '.join(drug_info['alternatives_ar'][:2])}\n"

            response += "\nâš ï¸ **Ø¨Ø¯ÙˆÙ† Ø¬Ø±Ø¹Ø© Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ - Ø§Ø³ØªØ´Ø± Ø§Ù„ØµÙŠØ¯Ù„ÙŠ Ù„Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©**"
        else:
            response = f"ğŸ’Š **{drug_info['name_en']} ({drug_info['name_ar']})**\n\n"
            response += f"ğŸ”¹ **Use:** {drug_info['general_use_en']}\n"
            response += f"ğŸ”¹ **Important warnings:** {', '.join(drug_info['warnings_en'][:2])}\n"

            if drug_info['alternatives_en']:
                response += f"ğŸ”¹ **General alternatives:** {', '.join(drug_info['alternatives_en'][:2])}\n"

            response += "\nâš ï¸ **No dosage provided - consult pharmacist for appropriate dose**"

        return response

    def handle_unclear_input(self, user_input: str, language: str) -> str:
        """Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø¨Ù‡Ù…Ø©"""
        if language == 'ar':
            return """ÙˆØ¶Ø­ Ø§Ù„Ø¹Ø±Ø¶ Ø£ÙƒØ«Ø± Ø¹Ø´Ø§Ù† Ø£ÙÙ‡Ù…:

**Ø­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:**
â€¢ Ø­Ø±Ø§Ø±Ø©ØŸ
â€¢ Ø£Ù„Ù…ØŸ 
â€¢ ÙƒØ­Ø©ØŸ
â€¢ Ø§Ù„ØªÙ‡Ø§Ø¨ØŸ
â€¢ Ø¯ÙˆØ®Ø©ØŸ
â€¢ Ù…ØºØµØŸ

Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¨ÙˆØ¶ÙˆØ­ Ù…Ø«Ù„: "Ø¹Ù†Ø¯ÙŠ ØµØ¯Ø§Ø¹" Ø£Ùˆ "ÙƒØ­Ø© Ù…Ù† ÙŠÙˆÙ…ÙŠÙ†""""
        else:
            return """Clarify the symptom more so I can understand:

**Specify the problem type:**
â€¢ Fever?
â€¢ Pain?
â€¢ Cough?
â€¢ Inflammation?
â€¢ Dizziness?
â€¢ Cramps?

Write the problem clearly like: "I have headache" or "Cough for 2 days""""

    def detect_language(self, text: str) -> str:
        """ÙƒØ´Ù Ù„ØºØ© Ø§Ù„Ù†Øµ"""
        arabic_chars = re.findall(r'[\u0600-\u06FF]', text)
        if len(arabic_chars) > len(text) * 0.3:
            return 'ar'
        return 'en'

class PrescriptionOCR:
    def __init__(self):
        self.reader = easyocr.Reader(['ar', 'en'])

    def extract_drug_info(self, image) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ù…Ù† Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ©"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ array
            img_array = np.array(image)

            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
            results = self.reader.readtext(img_array)

            extracted_text = []
            for (bbox, text, confidence) in results:
                if confidence > 0.5:  # ÙÙ‚Ø· Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
                    extracted_text.append(text)

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ÙˆØ§Ù„ØªØ±Ø§ÙƒÙŠØ²
            drugs_found = []
            drug_api = DrugAPIHandler()

            for text in extracted_text:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ±Ø§ÙƒÙŠØ² (mg, gm, ml)
                concentration_match = re.search(r'(\d+)\s*(mg|gm|ml|gram)', text.lower())

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©
                drug_info = drug_api.search_drug(text)
                if drug_info:
                    concentration = concentration_match.group() if concentration_match else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                    drugs_found.append({
                        'name': text,
                        'concentration': concentration,
                        'drug_info': drug_info
                    })

            return {
                'success': True,
                'drugs_found': drugs_found,
                'raw_text': extracted_text,
                'message_ar': f'ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(drugs_found)} Ø¯ÙˆØ§Ø¡ Ù…Ù† Ø§Ù„ÙˆØµÙØ©',
                'message_en': f'Extracted {len(drugs_found)} medications from prescription'
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message_ar': 'ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ©',
                'message_en': 'Failed to read prescription'
            }

def main():
    try:
        st.set_page_config(
            page_title="Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø¢Ù…Ù† Ù…Ø¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„Ø§Ù…Ø©",
            page_icon="ğŸ’Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©: {str(e)}")

    st.title("ğŸ’Š Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø¢Ù…Ù† Ù…Ø¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
    st.markdown("### Safe Medical Bot with Comprehensive Safety Rules | Ø¨ÙˆØª Ø·Ø¨ÙŠ Ø¢Ù…Ù† Ø¨Ù‚ÙˆØ§Ø¹Ø¯ Ø³Ù„Ø§Ù…Ø© Ø´Ø§Ù…Ù„Ø©")

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    if 'user_data' not in st.session_state:
        st.session_state.user_data = {}

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙˆØª
    if 'chatbot' not in st.session_state:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù…Ù† Ù…Ø¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„Ø§Ù…Ø©..."):
            try:
                st.session_state.chatbot = AdvancedMedicalChatbot()
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")
                st.stop()

    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.header("Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø·Ø¨Ù‚Ø© 100%")
        st.markdown("""
        ğŸš« **Ù…Ù…Ù†ÙˆØ¹ Ø¬Ø±Ø¹Ø§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„ Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹**

        ğŸš« **Ù…Ù…Ù†ÙˆØ¹ ÙˆØµÙ Ø¯ÙˆØ§Ø¡ Ù„Ù„Ø­Ø§Ù…Ù„**

        ğŸš¨ **ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ ÙÙˆØ±Ø§Ù‹**

        âœ… **Ù†ØµØ§Ø¦Ø­ Ø¹Ø§Ù…Ø© ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø¬Ø±Ø¹Ø§Øª**

        âœ… **Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø¨Ø¯ÙˆÙ† Ø¬Ø±Ø¹Ø©**

        âœ… **Decision Tree ÙˆØ§Ø¶Ø­**
        """)

        st.header("Ø±ÙØ¹ Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„ÙˆØµÙØ©...", type=['png', 'jpg', 'jpeg'])

    # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¢Ù…Ù†Ø© | Safe Chat Interface")

        # Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        if st.session_state.chat_history:
            st.subheader("Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© | Conversation")
            for i, (user_msg, bot_response, timestamp) in enumerate(st.session_state.chat_history):
                with st.container():
                    st.markdown(f"**Ø£Ù†Øª ({timestamp}):** {user_msg}")
                    st.markdown(f"**Ø§Ù„Ø¨ÙˆØª:** {bot_response}")
                    if i < len(st.session_state.chat_history) - 1:
                        st.markdown("---")

        # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        example_value = st.session_state.get('selected_example', '')
        if example_value:
            st.session_state.selected_example = ''

        user_input = st.text_area("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ):", 
                                 value=example_value,
                                 placeholder="Ù…Ø«Ø§Ù„: Ø¹Ù†Ø¯ÙŠ ØµØ¯Ø§Ø¹ØŒ Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø¨Ù†Ø¯ÙˆÙ„", 
                                 key="user_input_area")

        col_send, col_clear = st.columns([1, 1])

        with col_send:
            if st.button("Ø¥Ø±Ø³Ø§Ù„ | Send", type="primary"):
                if user_input:
                    process_user_message(user_input, uploaded_file)

        with col_clear:
            if st.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© | Clear Chat"):
                st.session_state.chat_history = []
                st.rerun()

    with col2:
        st.header("Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù†Ø´Ø·Ø©")
        st.success("âœ… ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„")
        st.success("âœ… ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø­ÙˆØ§Ù…Ù„") 
        st.success("âœ… ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦")
        st.success("âœ… Ù…Ù†Ø¹ Ø§Ù„Ø¬Ø±Ø¹Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹")
        st.success("âœ… Decision Tree ÙØ¹Ø§Ù„")

        # Ø£Ù…Ø«Ù„Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
        st.header("Ø£Ù…Ø«Ù„Ø© Ù„Ù„ØªØ¬Ø±Ø¨Ø©")
        examples = [
            "Ø¹Ù†Ø¯ÙŠ ØµØ¯Ø§Ø¹ Ø´Ø¯ÙŠØ¯",
            "ÙƒØ­Ø© Ù…Ù† ÙŠÙˆÙ…ÙŠÙ†", 
            "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø¨Ù†Ø¯ÙˆÙ„",
            "Ø¯ÙˆØ§Ø¡ Ù„Ù„Ø­Ø±Ø§Ø±Ø©",
            "Ø­Ù„Ù‚ÙŠ ÙŠÙ„Ø¹Ø¨"
        ]

        for example in examples:
            if st.button(f"Ø¬Ø±Ø¨: {example}", key=f"example_{hash(example)}"):
                st.session_state.selected_example = example
                st.rerun()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ©
    if uploaded_file:
        st.header("ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ©")
        process_prescription(uploaded_file)

def process_user_message(user_input: str, uploaded_file=None):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    chatbot = st.session_state.chatbot
    language = chatbot.detect_language(user_input)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù…Ù† Ø§Ù„Ø¬Ø¯ÙŠØ¯
    response = chatbot.process_query(user_input, language)

    # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.chat_history.append((user_input, response, timestamp))

    st.rerun()

def process_prescription(uploaded_file):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©"""
    ocr_processor = PrescriptionOCR()

    try:
        image = Image.open(uploaded_file)
        st.image(image, caption="Ø§Ù„ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", use_column_width=True)

        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙˆØµÙØ©..."):
            ocr_result = ocr_processor.extract_drug_info(image)

        if ocr_result['success']:
            st.success(ocr_result['message_ar'])

            if ocr_result['drugs_found']:
                st.subheader("Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ÙˆØµÙØ©:")

                for drug in ocr_result['drugs_found']:
                    with st.expander(f"ğŸ’Š {drug['name']} - {drug['concentration']}"):
                        drug_info = drug['drug_info']
                        st.write(f"**Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** {drug_info['general_use_ar']}")
                        st.write(f"**Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª:** {', '.join(drug_info['warnings_ar'])}")
                        st.write(f"**Ø§Ù„ØªØ¯Ø§Ø®Ù„Ø§Øª:** {', '.join(drug_info['interactions_ar'])}")

                        st.error("âš ï¸ **Ù…Ù…Ù†ÙˆØ¹ Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø±Ø¹Ø§Øª - Ø§Ø³ØªØ´Ø± Ø§Ù„ØµÙŠØ¯Ù„ÙŠ**")

            # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
            with st.expander("Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©"):
                st.write(ocr_result['raw_text'])

        else:
            st.error(ocr_result['message_ar'])

    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØµÙØ©: {str(e)}")

if __name__ == "__main__":
    main()